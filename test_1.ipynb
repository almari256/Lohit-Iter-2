{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "from openai import OpenAI\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = 'sk-proj-akdeZO2k0thnW5qqSQPiT3BlbkFJFVW45H5G0FVUuzST2rLo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('final_result.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the document\\'s information, \"Item 1. Business\" of the Form 10-K for Apple Inc. provides details about the Company\\'s business operations, financial condition, and operating results. It discusses the management of the business based on geographic segments such as Americas, Europe, Greater China, Japan, and Rest of Asia Pacific. It also delves into the external factors that can impact Apple Inc.\\'s business, including global economic conditions, suppliers, logistics providers, and competitive landscape. For a more in-depth analysis, you can refer to Part II, Item 7, \"Managementâ€™s Discussion and Analysis of Financial Condition and Results of Operations\" of the Form 10-K document. (Page 1-2, Apple Inc. Form 10-K)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[list(data.keys())[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "typer = 'Meddic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are a Discovery Question Generator \n",
    "\n",
    "- You will be provided with a topic \n",
    "- You will be provided with information of that topic \n",
    "- You will be provided with a type \n",
    "\n",
    "- Your task is to generate a list of discovery questions based on the topic , information and discovery question type seperated by '\\n'\n",
    "\n",
    "Topic : {}\n",
    "\n",
    "Information : {}\n",
    "\n",
    "Type : {}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_llm(prompt) :\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo' , \n",
    "        messages = [\n",
    "            {\n",
    "                'role' : 'user' , \n",
    "                'content' : prompt}] , \n",
    "        stream = True)\n",
    "    response = ''\n",
    "\n",
    "    for chunk in stream : \n",
    "\n",
    "        if chunk.choices[0].delta.content : response += chunk.choices[0].delta.content\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prompt = prompt.format(\n",
    "    list(data.keys())[0] , \n",
    "    data[list(data.keys())[0]] , \n",
    "    'Meddic'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = run_llm(sample_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"What is Apple Inc.'s market segment breakdown by geographic regions?\",\n",
       " \"How does global economic conditions impact Apple Inc.'s business operations?\",\n",
       " \"What are the key external factors that can affect Apple Inc.'s financial condition?\",\n",
       " 'How does Apple Inc. manage its suppliers and logistics providers?',\n",
       " \"What is Apple Inc.'s competitive landscape like and how does it impact their business strategy?\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are a Question Reframing expert \n",
    "\n",
    "- You will be provided with some context \n",
    "- You will be provided with a question \n",
    "- You will be provided with a Discovery Question Format\n",
    "\n",
    "- Your task is to reframe the question incorporating context and styling with Discovery Question Format \n",
    "\n",
    "Context : {}\n",
    "\n",
    "Question : {}\n",
    "\n",
    "Discovery Question Format : Meddic\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = FAISS.load_local(\n",
    "    'main_vector_db' , \n",
    "    embeddings = OpenAIEmbeddings(model = 'text-embedding-3-large') , \n",
    "    allow_dangerous_deserialization = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_docs = vc.similarity_search(response.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '\\n'.join([\n",
    "    doc.page_content \n",
    "    for doc \n",
    "    in similar_docs\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''\n",
    "You are a question framing specialist \n",
    "\n",
    "- You will be provided with some context \n",
    "- You will be provided with a query \n",
    "\n",
    "- Your task is to reframe the query embedding context into the new reframed query \n",
    "\n",
    "- Only return the single query and nothing else\n",
    "\n",
    "Context : {}\n",
    "\n",
    "Query : {}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt.format(context , response.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = run_llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How does Apple Inc. breakdown its market segments by geographic regions?'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
